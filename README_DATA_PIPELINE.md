# ğŸ“‘ Luá»“ng Xá»­ LÃ½ Dá»¯ Liá»‡u: Tá»« *Context* Äáº¿n *Evidence*

> **Má»¥c tiÃªu**: Giáº£i thÃ­ch chi tiáº¿t tá»«ng bÆ°á»›c há»‡ thá»‘ng chuyá»ƒn Ä‘á»•i *context* thÃ´ sang táº­p cÃ¢u *evidence* Ä‘Ã£ Ä‘Æ°á»£c xáº¿p háº¡ng, sá»­ dá»¥ng **Multi-Hop Multi-Beam Search** vÃ  **Advanced Filtering**.

---

## 1ï¸âƒ£ Nháº­p Liá»‡u & Tiá»n Xá»­ LÃ½

| BÆ°á»›c | ThÃ nh pháº§n | MÃ´ táº£ |
|------|------------|-------|
| 1.1 | **Input JSON** | `{ "context", "claim", "evidence", "label" }` |
| 1.2 | **Sentence Segmentation** | `VnCoreNLP` tÃ¡ch cÃ¢u trong *context* & *claim*. |
| 1.3 | **POS / NER / Parsing** | VnCoreNLP gÃ¡n `POS`, `NER`, `dep` cho tá»«ng token. |
| 1.4 | **Graph Construction** | Táº¡o `TextGraph` gá»“m **word nodes**, **sentence nodes**, **dependency edges**, **semantic edges**. |

**ğŸ” Chi tiáº¿t thá»±c thi**
- **1.1** Äá»c file JSON âœ kiá»ƒm tra schema, loáº¡i bá» báº£n ghi thiáº¿u trÆ°á»ng.
- **1.2** Gá»i `model.annotate_text()` Ä‘á»ƒ cáº¯t cÃ¢u (tiáº¿t kiá»‡m thá»i gian báº±ng batch).
- **1.3** DÃ¹ng cÃ¹ng `VnCoreNLP` output láº¥y `posTag`, `nerLabel`, `depParent`.
- **1.4** Khá»Ÿi táº¡o `TextGraph.build_from_vncorenlp_output()`:
  - ThÃªm *word nodes* + *sentence nodes*.
  - Táº¡o *dependency edges* giá»¯a tá»« phá»¥ thuá»™c & gá»‘c.
  - TÃ­nh *SBERT* & *PhoBERT* similarity giá»¯a cÃ¢u âœ *semantic edges*.

```mermaid
flowchart TD
    A[ğŸ¥¡ JSON Sample] --> B[VnCoreNLP]
    B --> C[Graph Builder]
    C --> D[Context Graph]
```

---

## 2ï¸âƒ£ TrÃ­ch Xuáº¥t Thá»±c Thá»ƒ (Entity Extraction)

| Nguá»“n | Ká»¹ thuáº­t | Äáº§u ra |
|-------|----------|--------|
| **Phrase-Based** | Pattern + POS trÃªn *claim* | Cá»¥m danh tá»«, tÃªn riÃªng |
| **OpenAI GPT-4o** | Prompt + Few-shot | Thá»±c thá»ƒ ngá»¯ cáº£nh |

**ğŸ” Chi tiáº¿t thá»±c thi**
- **2.1 Phrase-Based**
  - Lá»c chuá»—i danh tá»« (`Np`, `N`) liá»n ká» trong *claim*.
  - Loáº¡i bá» stopword & token â‰¤2 kÃ½ tá»±.
- **2.2 OpenAI**
  - GhÃ©p *context* rÃºt gá»n + *claim* âœ prompt "Liá»‡t kÃª entity".
  - Parse JSON response, chuáº©n hoÃ¡ chá»¯ thÆ°á»ng.
- **2.3 Merge & Dedup**
  - Gá»™p hai danh sÃ¡ch, dÃ¹ng `set(lower_strip)` loáº¡i trÃ¹ng.
  - Káº¿t quáº£ âœ `entities[]` + thÃªm node `entity_` vÃ o graph.

```mermaid
flowchart LR
    E1[Claim Phrase Entities] --merge--> M(ğŸŒ€ Merge)
    E2[OpenAI Context Entities] --merge--> M
    M --> E[Deduplicated Entity Set]
```

---

## 3ï¸âƒ£ Multi-Hop Multi-Beam Search

| Tham sá»‘ chÃ­nh | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh |
|---------------|------------------|
| `max_levels` | **4** |
| `beam_width_per_level` | **10** |
| `max_depth` | **50** |
| `num_hops` | **3** |

**ğŸ” Chi tiáº¿t thá»±c thi**
- **HOP 1**
  1. Chá»n *start nodes* = toÃ n bá»™ `entities[]` hoáº·c `root`.
  2. Gá»i `multi_level_beam_search_paths()` vá»›i `max_levels=4`.
  3. á» má»—i level, tÃ­nh SBERT sim, giá»¯ *Top-K* = `beam_width_per_level`.
  4. Gom táº¥t cáº£ path âœ `raw_sentences_hop1` (loáº¡i path â‰¤5 kÃ½ tá»±).
- **HOP 2..N**
  1. Láº·p qua tá»«ng cÃ¢u evidence hop trÆ°á»›c.
  2. Beam-search cÃ¡ nhÃ¢n báº¯t Ä‘áº§u tá»« node cÃ¢u Ä‘Ã³.
  3. Ãp dá»¥ng Level-filtering SBERT tÆ°Æ¡ng tá»±.
  4. ThÃªm vÃ o `all_accumulated_sentences` náº¿u chÆ°a xuáº¥t hiá»‡n.

```mermaid
flowchart TB
    subgraph Hop 1
        H1S[Start Nodes = Entities/Root] --> BS1[Beam Search]
    end
    subgraph Hop 2..N
        Hprev[Prev Hop Evidence] --> BSN[Beam Search]
    end
    BS1 & BSN --> COLLECT[ğŸ“¥ Accumulate Sentences]
```

---

## 4ï¸âƒ£ Bá»™ Lá»c NÃ¢ng Cao (Advanced Filtering)

Pipeline gá»“m **4 táº§ng**:
1. **Quality Check** â€“ Ä‘á»™ dÃ i, cáº¥u trÃºc, Ä‘á»‹nh dáº¡ng âœ `quality_score`.
2. **Semantic Relevance** â€“ SBERT/PhoBERT similarity âœ `relevance_score`.
3. **Entity Overlap** â€“ giao cáº¯t thá»±c thá»ƒ vá»›i *claim* âœ `entity_score`.
4. **NLI Stance** (tuá»³ chá»n) â€“ XLM-R xÃ¡c Ä‘á»‹nh `support` / `refute`.

**ğŸ” Chi tiáº¿t thá»±c thi**
- **Quality**: loáº¡i cÃ¢u <10 tá»«, nhiá»u kÃ½ tá»± Ä‘áº·c biá»‡t, hoáº·c thiáº¿u Ä‘á»™ng tá»«.
- **Semantic**: `cosine_similarity` â‰¥ threshold; fallback giá»¯ top-k náº¿u quÃ¡ Ã­t.
- **Entity**: TÃ­nh tá»‰ trá»ng token trÃ¹ng entity/claim, yÃªu cáº§u â‰¥ 0.05.
- **NLI**: Náº¿u báº­t, dÃ¹ng `xnli` tÃ­nh `support-prob` â€“ `refute-prob` â‰¥ `stance_delta`.

```mermaid
flowchart LR
    R[Raw Sentences] --> QF[Quality Filter] --> SF[Semantic Filter] --> EF[Entity Filter] --> NF[NLI Filter] --> F[Filtered Set]
```

---

## 5ï¸âƒ£ SBERT Reranking & Tá»•ng Há»£p

**ğŸ” Chi tiáº¿t thá»±c thi**
- Encode toÃ n bá»™ cÃ¢u & *claim* âœ embedding 768-D.
- TÃ­nh `cosine_similarity` âœ `final_sbert_score`.
- Sáº¯p xáº¿p giáº£m dáº§n, láº¥y `max_final_sentences` (máº·c Ä‘á»‹nh 25).
- Ghi nguá»“n hop, score & metadata vÃ o JSON output.

```mermaid
flowchart TD
    F[Filtered Set] --> RANK[SBERT Reranking]
    RANK --> TOPN[Select Top-N]
    TOPN --> OUT[ğŸ‰ Evidence]
```

---

## 6ï¸âƒ£ Äá»‹nh Dáº¡ng Káº¿t Quáº£

```jsonc
{
  "multi_level_evidence": [
    {
      "sentence": "Donald Trump sinh ngÃ y 14 thÃ¡ng 6 nÄƒm 1946...",
      "score": 0.87,
      "quality_score": 0.92,
      "relevance_score": 0.81,
      "final_sbert_score": 0.93,
      "source": "beam_search",
      "multi_hop_metadata": { "source_hop": 1 }
    }
  ],
  "statistics": {
    "coverage_percentage": 18.5,
    "hop_breakdown": {
      "hop_1": { "raw": 120, "filtered": 32 },
      "hop_2": { "raw": 58, "filtered": 12 }
    }
  }
}
```

---

## 7ï¸âƒ£ Tuá»³ Biáº¿n Nhanh

| Má»¥c tiÃªu | Tham sá»‘ CLI |
|----------|-------------|
| TÄƒng coverage | `--beam_width_per_level 15` |
| Giáº£m thá»i gian cháº¡y | `--max_depth 20` |
| Nháº¥n máº¡nh thá»±c thá»ƒ | `--use_entity_filtering` |
| Kiá»ƒm tra stance | `--use_contradiction_detection` |

---

## 8ï¸âƒ£ LÆ°á»£c Äá»“ Phá»¥ Thuá»™c ThÃ nh Pháº§n

```mermaid
flowchart LR
    subgraph Preprocessing
        A1[VnCoreNLP] --> G[TextGraph]
    end
    subgraph Reasoning
        G --> B1[Multi-Hop Beam Search]
        B1 --> C1[Advanced Filtering]
        C1 --> D1[SBERT Reranking]
    end
    D1 --> E1[Evidence JSON]
```

---

### ğŸ¤ ÄÃ³ng GÃ³p
ÄÃ³ng gÃ³p Ã½ tÆ°á»Ÿng hoáº·c pull request Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! Vui lÃ²ng táº¡o issue trÆ°á»›c khi PR.

### ğŸ“œ Giáº¥y PhÃ©p
MÃ£ nguá»“n phÃ¡t hÃ nh theo giáº¥y phÃ©p **MIT**. 